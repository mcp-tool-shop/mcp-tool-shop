name: Site quality checks

on:
  pull_request:
    paths:
      - 'site/**'
      - 'scripts/**'
      - 'tests/**'
      - 'submissions/**'
      - 'examples/**'
      - '.github/workflows/site-quality.yml'
  workflow_dispatch: {}

permissions:
  contents: read
  pull-requests: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: 22
          cache: npm
          cache-dependency-path: site/package-lock.json

      - name: Install root dependencies
        run: npm ci

      - run: npm ci
        working-directory: site

      # ── Unit + Invariant Tests ────────────────────────────────
      - name: Run unit tests
        run: npm test

      - name: Run invariant tests
        run: npm run test:invariants

      # ── Build ──────────────────────────────────────────────────
      - name: Build site
        run: npm run build
        working-directory: site

      # ── JSON Schema Validation ─────────────────────────────────
      - name: Validate overrides.json
        run: |
          node -e "
          const fs = require('fs');

          const VALID_KINDS = ['mcp-server', 'cli', 'library', 'plugin', 'desktop-app', 'vscode-extension', 'homebrew-tap', 'template', 'meta'];
          const VALID_STABILITY = ['stable', 'beta', 'experimental'];
          const VALID_CATEGORIES = ['mcp-core', 'voice', 'security', 'ml', 'infrastructure', 'desktop', 'devtools', 'web', 'games'];

          const overrides = JSON.parse(fs.readFileSync('site/src/data/overrides.json', 'utf8'));
          let errors = 0;

          for (const [repo, entry] of Object.entries(overrides)) {
            // kind enum
            if (entry.kind && !VALID_KINDS.includes(entry.kind)) {
              console.error('ERROR: ' + repo + '.kind = \"' + entry.kind + '\" (invalid)');
              errors++;
            }

            // stability enum
            if (entry.stability && !VALID_STABILITY.includes(entry.stability)) {
              console.error('ERROR: ' + repo + '.stability = \"' + entry.stability + '\" (invalid)');
              errors++;
            }

            // category enum
            if (entry.category && !VALID_CATEGORIES.includes(entry.category)) {
              console.error('ERROR: ' + repo + '.category = \"' + entry.category + '\" (invalid)');
              errors++;
            }

            // tagline length
            if (entry.tagline && entry.tagline.length > 90) {
              console.error('ERROR: ' + repo + '.tagline is ' + entry.tagline.length + ' chars (max 90)');
              errors++;
            }

            // tags max 6
            if (entry.tags && entry.tags.length > 6) {
              console.error('ERROR: ' + repo + '.tags has ' + entry.tags.length + ' items (max 6)');
              errors++;
            }

            // goodFor max 4
            if (entry.goodFor && entry.goodFor.length > 4) {
              console.error('ERROR: ' + repo + '.goodFor has ' + entry.goodFor.length + ' items (max 4)');
              errors++;
            }

            // notFor max 3
            if (entry.notFor && entry.notFor.length > 3) {
              console.error('ERROR: ' + repo + '.notFor has ' + entry.notFor.length + ' items (max 3)');
              errors++;
            }

            // screenshotType enum
            if (entry.screenshotType && !['real', 'placeholder'].includes(entry.screenshotType)) {
              console.error('ERROR: ' + repo + '.screenshotType = \"' + entry.screenshotType + '\" (must be real|placeholder)');
              errors++;
            }

            // screenshot path format
            if (entry.screenshot && !entry.screenshot.startsWith('/screenshots/')) {
              console.error('ERROR: ' + repo + '.screenshot must start with /screenshots/');
              errors++;
            }
          }

          if (errors > 0) {
            console.error('\n' + errors + ' validation error(s) found.');
            process.exit(1);
          } else {
            console.log('overrides.json: ' + Object.keys(overrides).length + ' entries, all valid.');
          }
          "

      # ── Collections Validation ─────────────────────────────────
      - name: Validate collections.json
        run: |
          node -e "
          const fs = require('fs');
          const collections = JSON.parse(fs.readFileSync('site/src/data/collections.json', 'utf8'));
          const projects = JSON.parse(fs.readFileSync('site/src/data/projects.json', 'utf8'));
          const projectRepos = new Set(projects.map(p => p.repo));
          let errors = 0;

          const ids = new Set();
          for (const col of collections) {
            // Unique IDs
            if (ids.has(col.id)) {
              console.error('ERROR: Duplicate collection id: ' + col.id);
              errors++;
            }
            ids.add(col.id);

            // Required fields
            if (!col.title) { console.error('ERROR: ' + col.id + ' missing title'); errors++; }
            if (!col.description) { console.error('ERROR: ' + col.id + ' missing description'); errors++; }
            if (!col.repos || col.repos.length === 0) { console.error('ERROR: ' + col.id + ' has no repos'); errors++; }

            // Repos exist in projects.json
            for (const repo of col.repos || []) {
              if (!projectRepos.has(repo)) {
                console.error('WARN: ' + col.id + ' references ' + repo + ' (not in projects.json)');
              }
            }
          }

          if (errors > 0) {
            console.error('\n' + errors + ' validation error(s) found.');
            process.exit(1);
          } else {
            console.log('collections.json: ' + collections.length + ' collections, all valid.');
          }
          "

      # ── Internal Link Check ────────────────────────────────────
      # Already scoped by PR paths filter. If this step exceeds ~5s,
      # consider caching results by dist hash or narrowing to changed pages.
      - name: Check internal links
        run: |
          node -e "
          const fs = require('fs');
          const path = require('path');

          const start = Date.now();
          const distDir = 'site/dist';
          let errors = 0;
          let checked = 0;

          function walkDir(dir) {
            const entries = fs.readdirSync(dir, { withFileTypes: true });
            for (const entry of entries) {
              const full = path.join(dir, entry.name);
              if (entry.isDirectory()) {
                walkDir(full);
              } else if (entry.name.endsWith('.html')) {
                checkFile(full);
              }
            }
          }

          function checkFile(file) {
            const html = fs.readFileSync(file, 'utf8');
            // Find internal href links
            const linkRe = /href=\"(\\/[^\"]*?)\"/g;
            let match;
            while ((match = linkRe.exec(html)) !== null) {
              const href = match[1];
              checked++;

              // Skip anchor-only links, external, and asset links
              if (href.startsWith('/#') || href.startsWith('/_astro/')) continue;

              // Normalize: /tools/ → /tools/index.html
              let target = href;
              if (target.endsWith('/')) target += 'index.html';
              if (!path.extname(target)) target += '/index.html';

              const fullPath = path.join(distDir, target);
              if (!fs.existsSync(fullPath)) {
                const relFile = path.relative(distDir, file);
                console.error('BROKEN LINK: ' + relFile + ' → ' + href);
                errors++;
              }
            }
          }

          walkDir(distDir);

          const elapsed = Date.now() - start;
          if (errors > 0) {
            console.error('\n' + errors + ' broken internal link(s) found in ' + checked + ' links checked (' + elapsed + 'ms).');
            process.exit(1);
          } else {
            console.log('Internal links: ' + checked + ' links checked, all valid (' + elapsed + 'ms).');
          }
          "

      # ── Ignore List Validation ─────────────────────────────────
      - name: Validate automation.ignore.json
        run: |
          node -e "
          const fs = require('fs');
          const ignoreList = JSON.parse(fs.readFileSync('site/src/data/automation.ignore.json', 'utf8'));

          if (!Array.isArray(ignoreList)) {
            console.error('ERROR: automation.ignore.json must be an array');
            process.exit(1);
          }

          const dupes = ignoreList.filter((item, i) => ignoreList.indexOf(item) !== i);
          if (dupes.length > 0) {
            console.error('ERROR: Duplicate entries in ignore list: ' + dupes.join(', '));
            process.exit(1);
          }

          console.log('automation.ignore.json: ' + ignoreList.length + ' entries, valid.');
          "

      # ── Submission Validation ─────────────────────────────────
      - name: Validate submissions
        run: node scripts/validate-submissions.mjs

      # ── Submission Lint + PR Comment ────────────────────────────
      - name: Lint submission PRs
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          CHANGED=$(git diff --name-only origin/${{ github.base_ref }}...HEAD -- 'submissions/*.json' 2>/dev/null || true)
          if [ -z "$CHANGED" ]; then
            echo "No submission files changed — skipping lint"
            exit 0
          fi
          echo "Linting changed submissions: $CHANGED"
          node scripts/lint-submission.mjs --ci --files $CHANGED
          if [ -f lint-report.md ]; then
            gh pr comment "${{ github.event.pull_request.number }}" --body-file lint-report.md
          fi

      # ── Projects Registry Flags ──────────────────────────────
      - name: Validate projects.json registry flags
        run: |
          node -e "
          const fs = require('fs');
          const projects = JSON.parse(fs.readFileSync('site/src/data/projects.json', 'utf8'));
          let errors = 0;
          let registered = 0;
          let unlisted = 0;

          let deprecated = 0;
          for (const p of projects) {
            if (typeof p.registered !== 'boolean') {
              console.error('ERROR: ' + p.repo + ' missing registered flag');
              errors++;
            }
            if (typeof p.unlisted !== 'boolean') {
              console.error('ERROR: ' + p.repo + ' missing unlisted flag');
              errors++;
            }
            if (typeof p.deprecated !== 'boolean') {
              console.error('ERROR: ' + p.repo + ' missing deprecated flag');
              errors++;
            }
            if (p.registered) registered++;
            if (p.unlisted) unlisted++;
            if (p.deprecated) deprecated++;
          }

          if (errors > 0) {
            console.error('\n' + errors + ' projects.json flag error(s).');
            process.exit(1);
          } else {
            console.log('projects.json: ' + projects.length + ' projects (' + registered + ' registered, ' + unlisted + ' unlisted, ' + deprecated + ' deprecated), flags valid.');
          }
          "

      # ── Registry Data Validation ──────────────────────────────
      - name: Validate registry data
        run: |
          node -e "
          const fs = require('fs');
          const path = require('path');
          const dir = 'site/src/data/registry';
          let errors = 0;

          // Check both files exist
          const files = ['registry.json', 'registry.index.json'];
          for (const f of files) {
            const p = path.join(dir, f);
            if (!fs.existsSync(p)) {
              console.error('MISSING: ' + p);
              errors++;
              continue;
            }

            // Validate JSON parses
            let data;
            try {
              data = JSON.parse(fs.readFileSync(p, 'utf8'));
            } catch (e) {
              console.error('INVALID JSON: ' + f + ' — ' + e.message);
              errors++;
              continue;
            }

            // Shape checks
            if (f === 'registry.json') {
              if (!data.schema_version) { console.error('ERROR: registry.json missing schema_version'); errors++; }
              if (!data.tools || !Array.isArray(data.tools)) { console.error('ERROR: registry.json missing tools array'); errors++; }
              else { console.log('registry.json: v' + data.schema_version + ', ' + data.tools.length + ' tools'); }
            }

            if (f === 'registry.index.json') {
              if (!Array.isArray(data)) { console.error('ERROR: registry.index.json must be an array'); errors++; }
              else { console.log('registry.index.json: ' + data.length + ' entries'); }
            }
          }

          if (errors > 0) {
            console.error('\n' + errors + ' registry validation error(s).');
            process.exit(1);
          }
          "

      # ── Secret Scan ─────────────────────────────────────────────
      - name: Scan dist for leaked secrets
        run: |
          node -e "
          const fs = require('fs');
          const path = require('path');

          const SECRET_PATTERNS = [
            { re: /ghp_[A-Za-z0-9_]{36,}/g, label: 'GitHub PAT' },
            { re: /gho_[A-Za-z0-9_]{36,}/g, label: 'GitHub OAuth' },
            { re: /github_pat_[A-Za-z0-9_]{22,}/g, label: 'GitHub fine-grained PAT' },
            { re: /AKIA[0-9A-Z]{16}/g, label: 'AWS Access Key' },
            { re: /sk-[A-Za-z0-9]{32,}/g, label: 'OpenAI/Stripe key' },
          ];

          let found = 0;
          function walk(dir) {
            for (const e of fs.readdirSync(dir, { withFileTypes: true })) {
              const full = path.join(dir, e.name);
              if (e.isDirectory()) { walk(full); continue; }
              if (!e.name.endsWith('.html') && !e.name.endsWith('.json') && !e.name.endsWith('.js')) continue;
              const content = fs.readFileSync(full, 'utf8');
              for (const { re, label } of SECRET_PATTERNS) {
                re.lastIndex = 0;
                if (re.test(content)) {
                  console.error('LEAKED SECRET (' + label + '): ' + path.relative('site/dist', full));
                  found++;
                }
              }
            }
          }
          walk('site/dist');
          if (found > 0) { console.error(found + ' potential secret(s) found in build output.'); process.exit(1); }
          else { console.log('Secret scan: clean (no leaked tokens in dist/).'); }
          "

      # ── Security Scan ────────────────────────────────────────────
      - name: Scan dist for dangerous URLs
        run: |
          node -e "
          const fs = require('fs');
          const path = require('path');
          const DANGEROUS_PROTOS = /(?:href|src|action)\s*=\s*[\"']?\s*(?:javascript|data|vbscript):/gi;
          let found = 0;
          function walk(dir) {
            for (const e of fs.readdirSync(dir, { withFileTypes: true })) {
              const full = path.join(dir, e.name);
              if (e.isDirectory()) { walk(full); continue; }
              if (!e.name.endsWith('.html')) continue;
              const content = fs.readFileSync(full, 'utf8');
              DANGEROUS_PROTOS.lastIndex = 0;
              let m;
              while ((m = DANGEROUS_PROTOS.exec(content)) !== null) {
                console.error('DANGEROUS URL in ' + path.relative('site/dist', full) + ': ' + m[0]);
                found++;
              }
            }
          }
          walk('site/dist');
          if (found > 0) { console.error(found + ' dangerous URL(s) found.'); process.exit(1); }
          else { console.log('Security scan: clean (no dangerous protocols in dist/).'); }
          "

  # ── Kit Pilot Org Validation ──────────────────────────────────
  kit-pilot:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: 22

      - name: Install root dependencies
        run: npm ci

      - name: Bootstrap pilot org
        env:
          KIT_CONFIG: ${{ github.workspace }}/examples/pilot-org/kit.config.json
        run: node scripts/kit-bootstrap.mjs

      - name: Self-test pilot org
        env:
          KIT_CONFIG: ${{ github.workspace }}/examples/pilot-org/kit.config.json
        run: node scripts/kit-selftest.mjs --skip-build --skip-invariants

      - name: Verify no org-specific strings leaked
        run: |
          if grep -r "mcp-tool-shop" examples/pilot-org/data/ 2>/dev/null; then
            echo "ERROR: org-specific strings found in pilot org data"
            exit 1
          fi
          echo "No org-specific string leaks detected."
